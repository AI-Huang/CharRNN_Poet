{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Date    : Mar-10-22 22:41\n",
    "# @Author  : Kelley Kan HUANG (kan.huang@connect.ust.hk)\n",
    "\n",
    "import torch\n",
    "from data import get_data\n",
    "from model import PoetryModel\n",
    "from config import Config\n",
    "opt = Config()\n",
    "opt.device = torch.device('cuda') if opt.use_gpu else torch.device('cpu')\n",
    "device = opt.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, word2ix, ix2word = get_data(opt)\n",
    "model = PoetryModel(len(word2ix), 128, 256).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(data,\n",
    "                                             batch_size=32,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1)\n",
    "\n",
    "data_ = next(iter(dataloader))\n",
    "data_ = data_.long().transpose(1, 0).contiguous()\n",
    "data_ = data_.to(device)\n",
    "input_, target = data_[:-1, :], data_[1:, :]\n",
    "\n",
    "output, _ = model(input_)  # Give dummy batch to forward().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "def resize_graph(dot, size_per_element=0.15, min_size=12):\n",
    "    \"\"\"Resize the graph according to how much content it contains.\n",
    "    Modify the graph in place.\n",
    "    \"\"\"\n",
    "    # Get the approximate number of nodes and edges\n",
    "    num_rows = len(dot.body)\n",
    "    content_size = num_rows * size_per_element\n",
    "    size = max(min_size, content_size)\n",
    "    size_str = str(size) + \",\" + str(size)\n",
    "    dot.graph_attr.update(size=size_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_dot(output, params=dict(list(model.named_parameters()))\n",
    "        #  ).render(\"./figure/PoetryModel\", format=\"png\")\n",
    "dot = make_dot(output, params=dict(list(model.named_parameters())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'figure\\\\PoetryModel.png'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_graph(dot, size_per_element=5, min_size=20)\n",
    "dot.format = \"png\"\n",
    "dot.render(\"./figure/PoetryModel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
